{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fa3d166-846c-4a0d-9699-09c73f83f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "252123e4-9c0b-4e4f-a4d6-81d0fe5c423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\X_PCA.npy')\n",
    "y = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\y_PCA.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e581ab4-573c-44c9-856e-900d34164a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_testVal, y_train, y_testVal = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_testVal, y_testVal, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7f05956-75a2-4068-b620-cf381ea97e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20711, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ff694d7-c5ca-4c15-8d14-8d9b03c6ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape = (1000, )),\n",
    "    tf.keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2649b62-5744-4d35-8431-e4302bc86813",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d449cdb-8326-480d-9df2-99324f94c936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "Epoch 2/10\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.6926 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "Epoch 3/10\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.6926 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5212\n",
      "Epoch 4/10\n",
      "648/648 [==============================] - 1s 991us/step - loss: 0.6926 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5212\n",
      "Epoch 5/10\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.6926 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "Epoch 6/10\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.6927 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "Epoch 7/10\n",
      "648/648 [==============================] - 1s 964us/step - loss: 0.6926 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "Epoch 8/10\n",
      "648/648 [==============================] - 1s 997us/step - loss: 0.6926 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "Epoch 9/10\n",
      "648/648 [==============================] - 1s 984us/step - loss: 0.6926 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5212\n",
      "Epoch 10/10\n",
      "648/648 [==============================] - 1s 987us/step - loss: 0.6926 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "139/139 [==============================] - 0s 658us/step - loss: 0.6923 - accuracy: 0.5212\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e7ecf45-1bce-4036-8654-92500472b7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.5211806893348694\n",
      "Loss :  0.6922646760940552\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : \", test_acc)\n",
    "print(\"Loss : \", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba27e78f-5659-461d-8576-39023cc75adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 0s 603us/step\n",
      "Porcentaje de confianza: [51.84041] %\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "probability_of_epilepsy = predictions[0]\n",
    "confidence_percentage = probability_of_epilepsy * 100\n",
    "print(\"Porcentaje de confianza:\", confidence_percentage, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a05cc8-cdf0-4b38-8b94-a86551066304",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFrecord_directory = 'C:\\\\Users\\\\47575909\\\\Desktop\\\\tfrecord_data_ejemplos' \n",
    "\n",
    "#lista de archivos TFRecord en la carpeta\n",
    "filenames = [os.path.join(TFrecord_directory, f) for f in os.listdir(TFrecord_directory) if f.endswith('.tfrecord')]\n",
    "\n",
    "#Hago un dataset de TensorFlow a partir de los archivos TFRecord\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "#función para parsear los datos de TFRecord\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        'grpno': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'path': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    return example\n",
    "\n",
    "parsed_dataset = dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "#batching para argar los datos en lotes\n",
    "batch_size = 5  #puedo cambiar el tamaño (en la PC del colegio el máximo es 16, pero capáz que le tengo que poner menos)\n",
    "batched_dataset = parsed_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6699f44-9941-4c97-9809-f8eca9e3254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/1 [00:22<?, ?it/s]\u001b[A\n",
      "\n",
      "5it [00:00, 34.33it/s]                                                                                                 \u001b[A\n",
      "10it [00:00, 28.19it/s]\u001b[A\n",
      "15it [00:00, 27.85it/s]\u001b[A\n",
      "20it [00:00, 26.46it/s]\u001b[A\n",
      "25it [00:00, 26.55it/s]\u001b[A\n",
      "30it [00:01, 25.98it/s]\u001b[A\n",
      "35it [00:01, 25.04it/s]\u001b[A\n",
      "40it [00:01, 25.75it/s]\u001b[A\n",
      "45it [00:01, 26.89it/s]\u001b[A\n",
      "50it [00:01, 26.41it/s]\u001b[A\n",
      "55it [00:02, 26.64it/s]\u001b[A\n",
      "60it [00:02, 27.06it/s]\u001b[A\n",
      "65it [00:02, 27.77it/s]\u001b[A\n",
      "70it [00:02, 27.30it/s]\u001b[A\n",
      "75it [00:02, 27.34it/s]\u001b[A\n",
      "80it [00:02, 28.31it/s]\u001b[A\n",
      "85it [00:03, 26.81it/s]\u001b[A\n",
      "90it [00:03, 26.73it/s]\u001b[A\n",
      "95it [00:03, 26.14it/s]\u001b[A\n",
      "100it [00:03, 26.85it/s]\u001b[A\n",
      "105it [00:03, 27.21it/s]\u001b[A\n",
      "110it [00:04, 27.19it/s]\u001b[A\n",
      "115it [00:04, 26.57it/s]\u001b[A\n",
      "120it [00:04, 26.76it/s]\u001b[A\n",
      "125it [00:04, 27.82it/s]\u001b[A\n",
      "130it [00:04, 27.24it/s]\u001b[A\n",
      "135it [00:04, 27.43it/s]\u001b[A\n",
      "140it [00:05, 27.33it/s]\u001b[A\n",
      "145it [00:05, 26.51it/s]\u001b[A\n",
      "150it [00:05, 25.45it/s]\u001b[A\n",
      "155it [00:05, 26.71it/s]\u001b[A\n",
      "160it [00:05, 26.54it/s]\u001b[A\n",
      "165it [00:06, 26.91it/s]\u001b[A\n",
      "170it [00:06, 27.33it/s]\u001b[A\n",
      "175it [00:06, 27.13it/s]\u001b[A\n",
      "180it [00:06, 27.13it/s]\u001b[A\n",
      "185it [00:06, 27.02it/s]\u001b[A\n",
      "190it [00:07, 26.99it/s]\u001b[A\n",
      "195it [00:07, 27.51it/s]\u001b[A\n",
      "200it [00:07, 27.64it/s]\u001b[A\n",
      "205it [00:07, 27.25it/s]\u001b[A\n",
      "210it [00:07, 26.48it/s]\u001b[A\n",
      "215it [00:07, 26.73it/s]\u001b[A\n",
      "220it [00:08, 27.29it/s]\u001b[A\n",
      "225it [00:08, 27.69it/s]\u001b[A\n",
      "230it [00:08, 27.17it/s]\u001b[A\n",
      "235it [00:08, 27.24it/s]\u001b[A\n",
      "240it [00:08, 27.16it/s]\u001b[A\n",
      "245it [00:09, 27.07it/s]\u001b[A\n",
      "250it [00:09, 28.08it/s]\u001b[A\n",
      "255it [00:09, 27.59it/s]\u001b[A\n",
      "260it [00:09, 27.59it/s]\u001b[A\n",
      "265it [00:09, 26.82it/s]\u001b[A\n",
      "270it [00:09, 27.61it/s]\u001b[A\n",
      "275it [00:10, 26.98it/s]\u001b[A\n",
      "280it [00:10, 27.00it/s]\u001b[A\n",
      "285it [00:10, 27.51it/s]\u001b[A\n",
      "290it [00:10, 26.97it/s]\u001b[A\n",
      "295it [00:10, 24.74it/s]\u001b[A\n",
      "300it [00:11, 24.27it/s]\u001b[A\n",
      "305it [00:11, 25.17it/s]\u001b[A\n",
      "309it [00:11, 26.85it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Define el número máximo de componentes principales que deseas mantener para todos los lotes\n",
    "max_components = 1000  # Puedes ajustar este valor según tus necesidades\n",
    "\n",
    "X_list = []  # Lista temporal para X\n",
    "y_list = []  # Lista temporal para y\n",
    "\n",
    "# Crea un objeto tqdm para rastrear el progreso\n",
    "pbar = tqdm(total=len(filenames))\n",
    "\n",
    "# Itera los lotes\n",
    "for batch_data in batched_dataset:\n",
    "    paths = batch_data['path'].numpy()\n",
    "    labels = batch_data['label'].numpy()\n",
    "    \n",
    "    # Cargar los scaleograms desde los archivos .npy\n",
    "    batch_X = []\n",
    "    for path in paths:\n",
    "        spectrogram = np.load(path.decode('utf-8'))\n",
    "        batch_X.append(spectrogram)\n",
    "    \n",
    "    # Convierte batch_X en un arreglo NumPy\n",
    "    batch_X = np.array(batch_X)\n",
    "    \n",
    "    batch_X = batch_X.reshape((batch_X.shape[0], -1))  # Aplanar los datos\n",
    "    \n",
    "    # NORMALIZA X en rango [-1, 1] para que el cero quede en el centro\n",
    "    min_val = np.min(batch_X)\n",
    "    max_val = np.max(batch_X)\n",
    "\n",
    "    batch_X = -1 + 2 * (batch_X - min_val) / (max_val - min_val)\n",
    "    \n",
    "    variance_to_keep = 0.95  # Me quedo con el 95% de la varianza\n",
    "\n",
    "    pca = PCA()\n",
    "    batch_X = pca.fit_transform(batch_X)  # Aplica PCA para los datos escalados\n",
    "\n",
    "    # Asegúrate de que todos los lotes tengan la misma cantidad de componentes principales\n",
    "    n_components_to_keep = min(max_components, batch_X.shape[1])\n",
    "    if batch_X.shape[1] < max_components:\n",
    "        # Rellena con ceros las columnas faltantes si es necesario\n",
    "        zeros_to_add = max_components - batch_X.shape[1]\n",
    "        zeros = np.zeros((batch_X.shape[0], zeros_to_add))\n",
    "        batch_X = np.hstack((batch_X, zeros))\n",
    "    else:\n",
    "        batch_X = batch_X[:, :n_components_to_keep]\n",
    "\n",
    "    # Agrega los scaleograms y labels a X_list e y_list\n",
    "    X_list.append(batch_X)\n",
    "    y_list.extend(labels)\n",
    "\n",
    "    # Actualiza la barra de progreso\n",
    "    pbar.update(len(paths))  # Actualiza la barra de progreso según la cantidad de archivos en el lote\n",
    "\n",
    "# Convierte X_list e y_list en arreglos NumPy\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.array(y_list)\n",
    "\n",
    "# Cierra la barra de progreso\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "972000c2-1290-4736-a4ff-64f8833409cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_shape = X.shape\n",
    "shape_0 = X_shape[0]\n",
    "X_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6985ffdb-a775-4d94-bbc4-b6494264769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(shape_0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e62937-d4a2-4ba6-b3de-f5cba245f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = np.min(X)\n",
    "max_val = np.max(X)\n",
    "\n",
    "X = -1 + 2 * (X - min_val) / (max_val - min_val)\n",
    "\n",
    "#X = (X - X.min()) / (X.max() - X.min()) [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf95e0b5-d05d-45cf-8cd3-828a26be059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ejemplo_epilepsia.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d58c9-ad07-4449-ab69-8967cbf1beaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
