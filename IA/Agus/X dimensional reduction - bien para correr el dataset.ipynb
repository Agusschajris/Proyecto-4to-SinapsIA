{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa5b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import ssqueezepy #para convertir la señal en imagen\n",
    "from ssqueezepy import cwt\n",
    "from ssqueezepy.visuals import plot, imshow\n",
    "import os\n",
    "import mne #eeg analysis library\n",
    "import scipy.io\n",
    "#import torch.nn as nn\n",
    "#import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934decab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b2431d-a06c-4017-9f3e-678e2187a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\X_PCA.npy')\n",
    "#y = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\y_PCA.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff810e27-4f43-46a5-bda0-439faa4f45f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355c3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
    "#PRUEBO CON MENOS DATOS\n",
    "#ACA SUBO LOS ARCHIVOS DE TFRECORD\n",
    "TFrecord_directory = 'C:\\\\Users\\\\47575909\\\\Desktop\\\\tfrecord_data' \n",
    "\n",
    "#lista de archivos TFRecord en la carpeta\n",
    "filenames = [os.path.join(TFrecord_directory, f) for f in os.listdir(TFrecord_directory) if f.endswith('.tfrecord')]\n",
    "\n",
    "#Hago un dataset de TensorFlow a partir de los archivos TFRecord\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "#función para parsear los datos de TFRecord\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        'grpno': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'path': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    return example\n",
    "\n",
    "parsed_dataset = dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "#batching para argar los datos en lotes\n",
    "batch_size = 2  #puedo cambiar el tamaño (en la PC del colegio el máximo es 16, pero capáz que le tengo que poner menos)\n",
    "batched_dataset = parsed_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bbfff93-a685-40d9-9d38-fdc04dbafcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec={'grpno': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'label': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'path': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecda7582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#SEPARO EN X E Y\\nX = []\\ny = []\\n\\n#itero los lotes\\nfor batch_data in batched_dataset:\\n    paths = batch_data['path'].numpy()\\n    labels = batch_data['label'].numpy()\\n    \\n    #cargo los scaleograms desde los archivos .npy\\n    batch_X = []\\n    for path in paths:\\n        spectrogram = np.load(path.decode('utf-8'))\\n        batch_X.append(spectrogram)\\n    \\n#//////NUEVO\\n\\n    #primero tengo que convertirlo en un archivo numpy porque sino no quiere\\n    batch_X = np.array(batch_X)\\n    \\n    X_shape = batch_X.shape\\n    shape_0 = X_shape[0]\\n\\n    # Aplanar\\n    batch_X = batch_X.reshape(shape_0, -1)\\n    \\n    #NORMALIZO X en rango [-1, 1] para que el cero quede en el centro\\n    min_val = np.min(batch_X)\\n    max_val = np.max(batch_X)\\n\\n    X = -1 + 2 * (batch_X - min_val) / (max_val - min_val)\\n    \\n    variance_to_keep = 0.95  #me quedo con el 95% de la varianza, esto es flexible (mientras más porcentaje, mayor va  quedar la dimensionalidad de mi X)\\n\\n    pca = PCA()\\n    batch_X = pca.fit_transform(batch_X)  #aplico pca para los datos escalados\\n\\n    #Encuentro el número mínimo de componentes principales para alcanzar la varianza deseada\\n    cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\\n    #('n_components_to_keep' contendrá el número mínimo de componentes principales necesarios para explicar al menos el 95% de la varianza en los datos.)\\n    n_components_to_keep = np.argmax(cumulative_variance_ratio >= variance_to_keep) + 1 #chona me dijo que me deberían quedar por ejemplo 1000 atributos\\n\\n    #Selecciono la cant de componentes principales que me salió\\n    batch_X = batch_X[:, :n_components_to_keep]\\n    \\n#//////NUEVO\\n    \\n    #agrego los scaleograms y labels a las listas X y y\\n    X.concatenate(batch_X)\\n    y.extend(labels)\\n\\n\\n#convierto X e y a formato .npy\\nX = np.concatenate(X, axis=0)\\ny = np.array(y)\\n\\nprint('Ya se separó todo!')\\nprint('Salió todo bien, tranquina :))')\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#SEPARO EN X E Y\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "#itero los lotes\n",
    "for batch_data in batched_dataset:\n",
    "    paths = batch_data['path'].numpy()\n",
    "    labels = batch_data['label'].numpy()\n",
    "    \n",
    "    #cargo los scaleograms desde los archivos .npy\n",
    "    batch_X = []\n",
    "    for path in paths:\n",
    "        spectrogram = np.load(path.decode('utf-8'))\n",
    "        batch_X.append(spectrogram)\n",
    "    \n",
    "#//////NUEVO\n",
    "\n",
    "    #primero tengo que convertirlo en un archivo numpy porque sino no quiere\n",
    "    batch_X = np.array(batch_X)\n",
    "    \n",
    "    X_shape = batch_X.shape\n",
    "    shape_0 = X_shape[0]\n",
    "\n",
    "    # Aplanar\n",
    "    batch_X = batch_X.reshape(shape_0, -1)\n",
    "    \n",
    "    #NORMALIZO X en rango [-1, 1] para que el cero quede en el centro\n",
    "    min_val = np.min(batch_X)\n",
    "    max_val = np.max(batch_X)\n",
    "\n",
    "    X = -1 + 2 * (batch_X - min_val) / (max_val - min_val)\n",
    "    \n",
    "    variance_to_keep = 0.95  #me quedo con el 95% de la varianza, esto es flexible (mientras más porcentaje, mayor va  quedar la dimensionalidad de mi X)\n",
    "\n",
    "    pca = PCA()\n",
    "    batch_X = pca.fit_transform(batch_X)  #aplico pca para los datos escalados\n",
    "\n",
    "    #Encuentro el número mínimo de componentes principales para alcanzar la varianza deseada\n",
    "    cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "    #('n_components_to_keep' contendrá el número mínimo de componentes principales necesarios para explicar al menos el 95% de la varianza en los datos.)\n",
    "    n_components_to_keep = np.argmax(cumulative_variance_ratio >= variance_to_keep) + 1 #chona me dijo que me deberían quedar por ejemplo 1000 atributos\n",
    "\n",
    "    #Selecciono la cant de componentes principales que me salió\n",
    "    batch_X = batch_X[:, :n_components_to_keep]\n",
    "    \n",
    "#//////NUEVO\n",
    "    \n",
    "    #agrego los scaleograms y labels a las listas X y y\n",
    "    X.concatenate(batch_X)\n",
    "    y.extend(labels)\n",
    "\n",
    "\n",
    "#convierto X e y a formato .npy\n",
    "X = np.concatenate(X, axis=0)\n",
    "y = np.array(y)\n",
    "\n",
    "print('Ya se separó todo!')\n",
    "print('Salió todo bien, tranquina :))')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ecba6-dfdf-414b-91be-cf5657d36b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define el número máximo de componentes principales que deseas mantener para todos los lotes\n",
    "max_components = 1000  # Puedes ajustar este valor según tus necesidades\n",
    "\n",
    "X_list = []  # Lista temporal para X\n",
    "y_list = []  # Lista temporal para y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7a6b96-d166-4df5-9b4f-3eba82ef5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_iter = iter(batched_dataset)\n",
    "batch_data = next(bd_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a31957f-9a85-487f-ab24-4321a63e6c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grpno': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([10, 10], dtype=int64)>,\n",
       " 'label': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 0], dtype=int64)>,\n",
       " 'path': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
       " array([b'C:\\\\Users\\\\47575909\\\\Desktop\\\\scaleogram\\\\subvideo_11/trial_0.npy',\n",
       "        b'C:\\\\Users\\\\47575909\\\\Desktop\\\\scaleogram\\\\subvideo_11/trial_1.npy'],\n",
       "       dtype=object)>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c5644a-fa51-4c43-9a18-230489f0f220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.99985725, -0.99985456, -0.9998539 , ..., -0.9989402 ,\n",
       "          -0.9989198 , -0.9989116 ],\n",
       "         [-0.9997775 , -0.9997736 , -0.99977314, ..., -0.9983727 ,\n",
       "          -0.99833775, -0.998324  ],\n",
       "         [-0.99966854, -0.99966335, -0.99966353, ..., -0.99761903,\n",
       "          -0.9975616 , -0.99753934],\n",
       "         ...,\n",
       "         [-0.994659  , -0.9946357 , -0.99461246, ..., -0.9908578 ,\n",
       "          -0.9908636 , -0.9908695 ],\n",
       "         [-0.96086556, -0.9608654 , -0.96086526, ..., -0.9608342 ,\n",
       "          -0.96083426, -0.9608343 ],\n",
       "         [-0.87473947, -0.87473947, -0.87473947, ..., -0.8747394 ,\n",
       "          -0.87473947, -0.87473947]],\n",
       "\n",
       "        [[-0.99991345, -0.9999164 , -0.9999175 , ..., -0.999667  ,\n",
       "          -0.9996697 , -0.9996768 ],\n",
       "         [-0.99988097, -0.99988747, -0.99989027, ..., -0.9994956 ,\n",
       "          -0.99949825, -0.9995087 ],\n",
       "         [-0.99984705, -0.99986124, -0.99986786, ..., -0.99927205,\n",
       "          -0.999273  , -0.9992872 ],\n",
       "         ...,\n",
       "         [-0.995192  , -0.9951628 , -0.9951334 , ..., -0.9862882 ,\n",
       "          -0.98628277, -0.9862775 ],\n",
       "         [-0.9325731 , -0.93257296, -0.9325729 , ..., -0.9325186 ,\n",
       "          -0.93251854, -0.9325185 ],\n",
       "         [-0.7841476 , -0.7841476 , -0.7841476 , ..., -0.7841476 ,\n",
       "          -0.7841476 , -0.7841476 ]],\n",
       "\n",
       "        [[-0.9981148 , -0.9981921 , -0.9982952 , ..., -0.9985538 ,\n",
       "          -0.9985757 , -0.99861574],\n",
       "         [-0.997058  , -0.99717844, -0.9973445 , ..., -0.997825  ,\n",
       "          -0.99785256, -0.99791217],\n",
       "         [-0.9956033 , -0.9957819 , -0.99603784, ..., -0.9968847 ,\n",
       "          -0.99691325, -0.9969963 ],\n",
       "         ...,\n",
       "         [-0.9688564 , -0.9686573 , -0.9684581 , ..., -0.9194791 ,\n",
       "          -0.9194671 , -0.9194558 ],\n",
       "         [-0.6221365 , -0.6221357 , -0.62213504, ..., -0.6218115 ,\n",
       "          -0.6218113 , -0.6218112 ],\n",
       "         [ 0.20963323,  0.20963335,  0.20963311, ...,  0.20963347,\n",
       "           0.20963311,  0.20963335]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9999227 , -0.9999305 , -0.9999386 , ..., -0.9997751 ,\n",
       "          -0.9997769 , -0.9997822 ],\n",
       "         [-0.9998865 , -0.9998996 , -0.9999136 , ..., -0.99966174,\n",
       "          -0.99966335, -0.9996712 ],\n",
       "         [-0.99984   , -0.99986106, -0.9998842 , ..., -0.9995147 ,\n",
       "          -0.9995148 , -0.9995257 ],\n",
       "         ...,\n",
       "         [-0.9952013 , -0.9951774 , -0.9951533 , ..., -0.9868378 ,\n",
       "          -0.98683167, -0.98682564],\n",
       "         [-0.93268204, -0.932682  , -0.9326819 , ..., -0.9326323 ,\n",
       "          -0.9326323 , -0.93263227],\n",
       "         [-0.7845017 , -0.7845017 , -0.7845016 , ..., -0.7845017 ,\n",
       "          -0.7845017 , -0.7845017 ]],\n",
       "\n",
       "        [[-0.9998467 , -0.9998429 , -0.99984103, ..., -0.99891686,\n",
       "          -0.9988951 , -0.998886  ],\n",
       "         [-0.9997589 , -0.99975353, -0.99975157, ..., -0.99833816,\n",
       "          -0.9983011 , -0.9982859 ],\n",
       "         [-0.9996379 , -0.9996308 , -0.9996295 , ..., -0.9975705 ,\n",
       "          -0.9975098 , -0.9974854 ],\n",
       "         ...,\n",
       "         [-0.9963832 , -0.9963675 , -0.9963518 , ..., -0.9936978 ,\n",
       "          -0.9937014 , -0.993705  ],\n",
       "         [-0.97127897, -0.9712789 , -0.9712788 , ..., -0.9712583 ,\n",
       "          -0.97125834, -0.9712584 ],\n",
       "         [-0.90807116, -0.90807116, -0.90807116, ..., -0.90807116,\n",
       "          -0.90807116, -0.90807116]],\n",
       "\n",
       "        [[-0.999851  , -0.99986213, -0.99987423, ..., -0.9998928 ,\n",
       "          -0.9998876 , -0.9998826 ],\n",
       "         [-0.9997824 , -0.9998009 , -0.9998214 , ..., -0.9998521 ,\n",
       "          -0.99984396, -0.99983627],\n",
       "         [-0.99969625, -0.99972564, -0.999759  , ..., -0.9998081 ,\n",
       "          -0.9997961 , -0.99978524],\n",
       "         ...,\n",
       "         [-0.9918049 , -0.9918184 , -0.9918318 , ..., -0.98727614,\n",
       "          -0.9872577 , -0.98723936],\n",
       "         [-0.91157824, -0.9115783 , -0.91157836, ..., -0.91155434,\n",
       "          -0.9115542 , -0.9115541 ],\n",
       "         [-0.71698797, -0.71698797, -0.71698797, ..., -0.71698797,\n",
       "          -0.71698797, -0.71698797]]],\n",
       "\n",
       "\n",
       "       [[[-0.99993956, -0.9999412 , -0.99994355, ..., -0.99984324,\n",
       "          -0.9998418 , -0.9998425 ],\n",
       "         [-0.9999063 , -0.9999088 , -0.99991244, ..., -0.9997589 ,\n",
       "          -0.99975616, -0.999757  ],\n",
       "         [-0.9998614 , -0.99986494, -0.99987024, ..., -0.99964625,\n",
       "          -0.9996412 , -0.999642  ],\n",
       "         ...,\n",
       "         [-0.99199057, -0.99197626, -0.9919621 , ..., -0.9925114 ,\n",
       "          -0.9925281 , -0.9925449 ],\n",
       "         [-0.9670726 , -0.9670725 , -0.9670723 , ..., -0.9670781 ,\n",
       "          -0.96707827, -0.96707845],\n",
       "         [-0.8946749 , -0.89467484, -0.8946749 , ..., -0.89467484,\n",
       "          -0.8946749 , -0.89467484]],\n",
       "\n",
       "        [[-0.99977463, -0.99978095, -0.99978894, ..., -0.9999247 ,\n",
       "          -0.99992746, -0.99993116],\n",
       "         [-0.99965316, -0.99966246, -0.9996744 , ..., -0.99988884,\n",
       "          -0.9998931 , -0.999899  ],\n",
       "         [-0.9994925 , -0.9995053 , -0.999522  , ..., -0.9998436 ,\n",
       "          -0.99984974, -0.9998587 ],\n",
       "         ...,\n",
       "         [-0.9861915 , -0.9861809 , -0.98617035, ..., -0.9913764 ,\n",
       "          -0.9914112 , -0.9914461 ],\n",
       "         [-0.9424094 , -0.9424093 , -0.94240916, ..., -0.9424544 ,\n",
       "          -0.94245464, -0.9424549 ],\n",
       "         [-0.8158171 , -0.8158171 , -0.8158171 , ..., -0.8158171 ,\n",
       "          -0.8158171 , -0.8158171 ]],\n",
       "\n",
       "        [[-0.9989686 , -0.99899983, -0.99904084, ..., -0.99972516,\n",
       "          -0.99973345, -0.99974316],\n",
       "         [-0.99841857, -0.9984655 , -0.99852806, ..., -0.99960846,\n",
       "          -0.99962175, -0.99963766],\n",
       "         [-0.99769086, -0.9977567 , -0.99784595, ..., -0.9994725 ,\n",
       "          -0.99949265, -0.99951744],\n",
       "         ...,\n",
       "         [-0.9206775 , -0.9206113 , -0.92054594, ..., -0.94901365,\n",
       "          -0.94921184, -0.9494105 ],\n",
       "         [-0.67409706, -0.67409635, -0.6740955 , ..., -0.67434955,\n",
       "          -0.6743509 , -0.6743523 ],\n",
       "         [ 0.04226804,  0.0422678 ,  0.04226792, ...,  0.0422678 ,\n",
       "           0.04226792,  0.04226792]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9998825 , -0.9998828 , -0.9998834 , ..., -0.99983   ,\n",
       "          -0.9998281 , -0.9998278 ],\n",
       "         [-0.9998221 , -0.9998224 , -0.99982274, ..., -0.9997421 ,\n",
       "          -0.99973875, -0.99973816],\n",
       "         [-0.99974567, -0.9997456 , -0.9997449 , ..., -0.99962807,\n",
       "          -0.9996226 , -0.99962145],\n",
       "         ...,\n",
       "         [-0.9871492 , -0.98713344, -0.9871179 , ..., -0.9902396 ,\n",
       "          -0.9902698 , -0.9903    ],\n",
       "         [-0.94553834, -0.94553816, -0.945538  , ..., -0.9455669 ,\n",
       "          -0.9455672 , -0.94556737],\n",
       "         [-0.82581025, -0.82581025, -0.82581025, ..., -0.82581025,\n",
       "          -0.82581025, -0.82581025]],\n",
       "\n",
       "        [[-0.99999213, -0.99999815, -0.9999931 , ..., -0.99998385,\n",
       "          -0.99998206, -0.99998003],\n",
       "         [-0.99998647, -0.999994  , -0.99998784, ..., -0.9999726 ,\n",
       "          -0.9999701 , -0.9999674 ],\n",
       "         [-0.99996984, -0.99997574, -0.9999709 , ..., -0.99995613,\n",
       "          -0.999953  , -0.9999495 ],\n",
       "         ...,\n",
       "         [-0.99464417, -0.9946334 , -0.9946226 , ..., -0.9946081 ,\n",
       "          -0.9946188 , -0.9946295 ],\n",
       "         [-0.977116  , -0.97711587, -0.97711575, ..., -0.97711563,\n",
       "          -0.97711575, -0.9771158 ],\n",
       "         [-0.92679375, -0.92679375, -0.92679375, ..., -0.92679375,\n",
       "          -0.92679375, -0.92679375]],\n",
       "\n",
       "        [[-0.99966836, -0.99967045, -0.99967474, ..., -0.9999816 ,\n",
       "          -0.99998075, -0.99998015],\n",
       "         [-0.99949634, -0.9994995 , -0.9995062 , ..., -0.999974  ,\n",
       "          -0.99997246, -0.9999714 ],\n",
       "         [-0.9992742 , -0.99927866, -0.99928844, ..., -0.99996525,\n",
       "          -0.99996257, -0.99996066],\n",
       "         ...,\n",
       "         [-0.9874821 , -0.98746777, -0.98745364, ..., -0.9908046 ,\n",
       "          -0.9908344 , -0.9908643 ],\n",
       "         [-0.9466267 , -0.94662654, -0.9466264 , ..., -0.9466568 ,\n",
       "          -0.94665706, -0.9466573 ],\n",
       "         [-0.8292924 , -0.8292924 , -0.8292924 , ..., -0.8292925 ,\n",
       "          -0.8292925 , -0.8292924 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = batch_data['path'].numpy()\n",
    "labels = batch_data['label'].numpy()\n",
    "\n",
    "# Cargar los scaleograms desde los archivos .npy\n",
    "batch_X = []\n",
    "for path in paths:\n",
    "    spectrogram = np.load(path.decode('utf-8'))\n",
    "    batch_X.append(spectrogram)\n",
    "\n",
    "batch_X = np.array(batch_X)\n",
    "    \n",
    "# batch_X = batch_X.reshape((batch_X.shape[0], -1))  # Aplanar los datos\n",
    "\n",
    "# NORMALIZA X en rango [-1, 1] para que el cero quede en el centro\n",
    "min_val = np.min(batch_X)\n",
    "max_val = np.max(batch_X)\n",
    "\n",
    "batch_X = -1 + 2 * (batch_X - min_val) / (max_val - min_val)\n",
    "\n",
    "batch_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70812a9a-a4a8-4893-8530-5f754698a3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pacmap\n",
      "  Obtaining dependency information for pacmap from https://files.pythonhosted.org/packages/18/12/59cfb926d2105a14eb2149a5741558fdedc0eeb3f46328feec1245d084e7/pacmap-0.7.1-py3-none-any.whl.metadata\n",
      "  Downloading pacmap-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\47575909\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pacmap) (1.3.2)\n",
      "Requirement already satisfied: numba>=0.57 in c:\\users\\47575909\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pacmap) (0.58.1)\n",
      "Collecting annoy>=1.11 (from pacmap)\n",
      "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
      "     ---------------------------------------- 0.0/647.5 kB ? eta -:--:--\n",
      "     - ----------------------------------- 30.7/647.5 kB 660.6 kB/s eta 0:00:01\n",
      "     ------ ------------------------------- 112.6/647.5 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 647.5/647.5 kB 6.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\47575909\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pacmap) (1.26.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\47575909\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.57->pacmap) (0.41.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\47575909\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20->pacmap) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\47575909\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20->pacmap) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\47575909\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20->pacmap) (3.2.0)\n",
      "Downloading pacmap-0.7.1-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: annoy\n",
      "  Building wheel for annoy (setup.py): started\n",
      "  Building wheel for annoy (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for annoy\n",
      "Failed to build annoy\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [14 lines of output]\n",
      "  C:\\Users\\47575909\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-311\n",
      "  creating build\\lib.win-amd64-cpython-311\\annoy\n",
      "  copying annoy\\__init__.py -> build\\lib.win-amd64-cpython-311\\annoy\n",
      "  copying annoy\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\annoy\n",
      "  copying annoy\\py.typed -> build\\lib.win-amd64-cpython-311\\annoy\n",
      "  running build_ext\n",
      "  building 'annoy.annoylib' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for annoy\n",
      "ERROR: Could not build wheels for annoy, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pacmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "660c1527-7e8e-45b6-a32e-42ae0e7a8eb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pacmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpacmap\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pacmap'"
     ]
    }
   ],
   "source": [
    "import pacmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09073f6c-66ca-4c7e-88da-79ddaad85b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 230, 384)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a21cb9-a2f7-499e-8675-c9c117019d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1236480), (2,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1951e425-3a2e-4db1-a8c5-79aab9bb531a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.99985725, -0.99985456, -0.9998539 , ..., -0.99991643,\n",
       "         -0.99991775, -0.9999196 ],\n",
       "        [-0.99992204, -0.999925  , -0.9999283 , ..., -0.9999353 ,\n",
       "         -0.99993604, -0.9999361 ],\n",
       "        [-0.9999355 , -0.9999346 , -0.9999341 , ..., -0.99990755,\n",
       "         -0.9999017 , -0.9998941 ],\n",
       "        ...,\n",
       "        [-0.9664635 , -0.96722597, -0.9679918 , ..., -0.99134135,\n",
       "         -0.99110097, -0.9908375 ],\n",
       "        [-0.9905519 , -0.9902452 , -0.98991853, ..., -0.98797005,\n",
       "         -0.988031  , -0.98809224],\n",
       "        [-0.9881534 , -0.98821443, -0.9882751 , ..., -0.9532691 ,\n",
       "         -0.9527509 , -0.9522377 ]],\n",
       "\n",
       "       [[-0.9517298 , -0.9512274 , -0.95073086, ..., -0.9882792 ,\n",
       "         -0.98808426, -0.98788995],\n",
       "        [-0.98769647, -0.98750395, -0.9873127 , ..., -0.9355713 ,\n",
       "         -0.935637  , -0.93570983],\n",
       "        [-0.93578964, -0.9358762 , -0.93596923, ..., -0.9767152 ,\n",
       "         -0.9765628 , -0.97640944],\n",
       "        ...,\n",
       "        [-0.9934355 , -0.9931943 , -0.9930401 , ..., -0.99930894,\n",
       "         -0.99916166, -0.9990153 ],\n",
       "        [-0.99888384, -0.9987729 , -0.9986812 , ..., -0.9947579 ,\n",
       "         -0.9950346 , -0.9953644 ],\n",
       "        [-0.9957412 , -0.9961577 , -0.9966061 , ..., -0.99257207,\n",
       "         -0.9914929 , -0.99048024]],\n",
       "\n",
       "       [[-0.9895745 , -0.9888145 , -0.98823476, ..., -0.9993674 ,\n",
       "         -0.9990912 , -0.9986538 ],\n",
       "        [-0.99812603, -0.9975303 , -0.99687654, ..., -0.9940068 ,\n",
       "         -0.9945086 , -0.9950303 ],\n",
       "        [-0.9955584 , -0.99608165, -0.9965906 , ..., -0.9987686 ,\n",
       "         -0.99897695, -0.99916184],\n",
       "        ...,\n",
       "        [-0.97464657, -0.9744754 , -0.97430634, ..., -0.95719117,\n",
       "         -0.95709145, -0.95699257],\n",
       "        [-0.95689464, -0.9567977 , -0.95670176, ..., -0.9713106 ,\n",
       "         -0.9713223 , -0.9713356 ],\n",
       "        [-0.9713505 , -0.97136694, -0.9713849 , ..., -0.9577977 ,\n",
       "         -0.95779127, -0.9577875 ]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.resize(batch_X[0], (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52bed504-bc82-4027-880f-6b25822093c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 88320)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1d =  np.array([features_2d.flatten() for features_2d in batch_X[0]])\n",
    "data_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64500daf-a296-462c-b5ca-0b42e1fca74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 88320), (14, 14))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance_to_keep = 0.95  # Me quedo con el 95% de la varianza\n",
    "n_components = 14\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "data_reduced = pca.fit_transform(data_1d)\n",
    "data_1d.shape, data_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b294652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12488it [05:03, 34.58it/s]                                                                                             "
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.43 MiB for an array with shape (2, 1236480) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m min_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(batch_X)\n\u001b[0;32m     30\u001b[0m max_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(batch_X)\n\u001b[1;32m---> 32\u001b[0m batch_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_val\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m (max_val \u001b[38;5;241m-\u001b[39m min_val)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''variance_to_keep = 0.95  # Me quedo con el 95% de la varianza\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03mpca = PCA()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03melse:\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    batch_X = batch_X[:, :n_components_to_keep]'''\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Agrega los scaleograms y labels a X_list e y_list\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.43 MiB for an array with shape (2, 1236480) and data type float32"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crea un objeto tqdm para rastrear el progreso\n",
    "pbar = tqdm(total=len(filenames))\n",
    "\n",
    "# Itera los lotes\n",
    "for batch_data in batched_dataset:\n",
    "    paths = batch_data['path'].numpy()\n",
    "    labels = batch_data['label'].numpy()\n",
    "    \n",
    "    # Cargar los scaleograms desde los archivos .npy\n",
    "    batch_X = []\n",
    "    for path in paths:\n",
    "        spectrogram = np.load(path.decode('utf-8'))\n",
    "        batch_X.append(spectrogram)\n",
    "    \n",
    "    # Convierte batch_X en un arreglo NumPy\n",
    "    batch_X = np.array(batch_X)\n",
    "    \n",
    "    batch_X = batch_X.reshape((batch_X.shape[0], -1))  # Aplanar los datos\n",
    "    \n",
    "    # NORMALIZA X en rango [-1, 1] para que el cero quede en el centro\n",
    "    min_val = np.min(batch_X)\n",
    "    max_val = np.max(batch_X)\n",
    "\n",
    "    batch_X = -1 + 2 * (batch_X - min_val) / (max_val - min_val)\n",
    "    \n",
    "    variance_to_keep = 0.95  # Me quedo con el 95% de la varianza\n",
    "    n_components = 3\n",
    "    pca = PCA(n_components=n_components)\n",
    "    batch_X = pca.fit_transform(batch_X)  # Aplica PCA para los datos escalados\n",
    "    \n",
    "    '''\n",
    "    # Asegúrate de que todos los lotes tengan la misma cantidad de componentes principales\n",
    "    n_components_to_keep = min(max_components, batch_X.shape[1])\n",
    "    if batch_X.shape[1] < max_components:\n",
    "        # Rellena con ceros las columnas faltantes si es necesario\n",
    "        zeros_to_add = max_components - batch_X.shape[1]\n",
    "        zeros = np.zeros((batch_X.shape[0], zeros_to_add))\n",
    "        batch_X = np.hstack((batch_X, zeros))\n",
    "    else:\n",
    "        batch_X = batch_X[:, :n_components_to_keep]'''\n",
    "\n",
    "    # Agrega los scaleograms y labels a X_list e y_list\n",
    "    X_list.append(batch_X)\n",
    "    y_list.extend(labels)\n",
    "\n",
    "    # Actualiza la barra de progreso\n",
    "    pbar.update(len(paths))  # Actualiza la barra de progreso según la cantidad de archivos en el lote\n",
    "\n",
    "# Convierte X_list e y_list en arreglos NumPy\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.array(y_list)\n",
    "\n",
    "# Cierra la barra de progreso\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8d00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12490it [05:20, 34.58it/s]"
     ]
    }
   ],
   "source": [
    "#LOS GUARDO EN MI COMPUTADORA\n",
    "#np.save('X.npy', X) está guardada normalizada en rango [0, 1], habría que cambiar eso\n",
    "np.save('X.npy', X)\n",
    "np.save('y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ec6cf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29588, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_shape = X.shape\n",
    "shape_0 = X_shape[0]\n",
    "X_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f01d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanar tus datos\n",
    "X = X.reshape(shape_0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e04607dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZO X en rango [-1, 1] para que el cero quede en el centro\n",
    "min_val = np.min(X)\n",
    "max_val = np.max(X)\n",
    "\n",
    "X = -1 + 2 * (X - min_val) / (max_val - min_val)\n",
    "\n",
    "#X = (X - X.min()) / (X.max() - X.min()) [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b37cbb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29588, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49216ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.decomposition import PCA\\n\\nvariance_to_keep = 0.95  #me quedo con el 95% de la varianza, esto es flexible (mientras más porcentaje, mayor va  quedar la dimensionalidad de mi X)\\n\\npca = PCA()\\nX = pca.fit_transform(X)  #aplico pca para los datos escalados\\n\\n#Encuentro el número mínimo de componentes principales para alcanzar la varianza deseada\\ncumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\\n#('n_components_to_keep' contendrá el número mínimo de componentes principales necesarios para explicar al menos el 95% de la varianza en los datos.)\\nn_components_to_keep = np.argmax(cumulative_variance_ratio >= variance_to_keep) + 1 #chona me dijo que me deberían quedar por ejemplo 1000 atributos\\n\\n#Selecciono la cant de componentes principales que me salió\\nX = X[:, :n_components_to_keep]\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.decomposition import PCA\n",
    "\n",
    "variance_to_keep = 0.95  #me quedo con el 95% de la varianza, esto es flexible (mientras más porcentaje, mayor va  quedar la dimensionalidad de mi X)\n",
    "\n",
    "pca = PCA()\n",
    "X = pca.fit_transform(X)  #aplico pca para los datos escalados\n",
    "\n",
    "#Encuentro el número mínimo de componentes principales para alcanzar la varianza deseada\n",
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "#('n_components_to_keep' contendrá el número mínimo de componentes principales necesarios para explicar al menos el 95% de la varianza en los datos.)\n",
    "n_components_to_keep = np.argmax(cumulative_variance_ratio >= variance_to_keep) + 1 #chona me dijo que me deberían quedar por ejemplo 1000 atributos\n",
    "\n",
    "#Selecciono la cant de componentes principales que me salió\n",
    "X = X[:, :n_components_to_keep]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eded711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"Me quedé con \" + str(n_components_to_keep) + \" componentes principales\")\\nX.shape'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(\"Me quedé con \" + str(n_components_to_keep) + \" componentes principales\")\n",
    "X.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ceaef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"Varianza explicada por cada componente principal:\", pca.explained_variance_ratio_)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(\"Varianza explicada por cada componente principal:\", pca.explained_variance_ratio_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no se si lo que hice está bien, chona me dijo que usara PaCMAP pero no lo entiendo, y acá encontre que con sklearn medio que se puede hacer asi que :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hago una función?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
