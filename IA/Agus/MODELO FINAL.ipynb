{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo definitivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHONA ME DIJO QUE USARA LOS DATOS SIN PCA Y QUE HAGA UN POOLING GRANDE AL PRINCIPIO DE LA CNN PARA ACHICAR LOS DATOS DE UNA CUANDO ENTRAN. \n",
    "ADEMÁS, TENGO QUE HACER CONV2D EN VES DE 1D Y TENGO QUE AGREGARLE LOS NUEVOS DATOS. ADEMÁS TENGO QUE USAR EL PRETRAINED MODEL RESNET QUE USO \n",
    "EL INDIO EN EL VIDEO PARA TENER YO YA HECHO EL COSO Y CON LOS WEIGHTS Y QUE NO ME TRADE TANTO EL ENTRENAMIENTO. YO LE CAMBIARÍA LO DEL POOL AL \n",
    "PRINCIPIO Y LO ADAPTARÍA AL FINAL DE LA RED PARA QUE SE AJUSTE A MIS DATOS.\n",
    "- TENGO QUE CORRER EL CODIGO PARA EL DATASET DE NUEVO PERO SIN EL PCA \n",
    "- VOLVER A ARREGLAR LA CNN PARA QUE ADMITA LA VIEJA INPUT SHAPE\n",
    "- USAR UN MODELO RESNET PREENTRENADO CON DATOS COHERENTES (PREFERENTEMENTE EL QUE USÓ EL INDIO)\n",
    "- INCORPORAR LO QUE ME DIJO CHONA DE CONV2D Y UN POOLING PARA QUE SE ADAPTE A RESNET (AdaptiveAvgPool2d - https://stackoverflow.com/questions/61955991/change-input-shape-dimensions-for-resnet-model-pytorch)\n",
    "\n",
    "CODIGOS DEL INDIO:\n",
    "https://github.com/talhaanwarch/youtube-tutorials/blob/main/eeg-conv2d.ipynb\n",
    "https://github.com/talhaanwarch/youtube-tutorials/blob/main/eeg_epilepsy.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, GlobalAveragePooling2D, MaxPooling2D, Dropout, Input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "#import tensorflowjs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\47575909/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import wandb\n",
    "import random\n",
    "wandb.login(key=\"3750a6378bb91e331366851db2db2f8b674797f6\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a39cad6f15d46a3bda2d1676b38ea19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: C:\\Users\\47575909\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py 848 getcaller\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Inicializa una ejecución de WandB\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSinapsIA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mschajrisgaratiagustina\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Configura hiperparámetros\u001b[39;00m\n\u001b[0;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:1189\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n\u001b[0;32m   1188\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterrupted\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m-> 1189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1191\u001b[0m     error_seen \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:1166\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1164\u001b[0m except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1166\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:752\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    749\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommunicating run to backend with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m second timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    751\u001b[0m run_init_handle \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mdeliver_run(run)\n\u001b[1;32m--> 752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_init_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_progress_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcancel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    758\u001b[0m     run_result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mrun_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py:283\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[1;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interface\u001b[38;5;241m.\u001b[39m_transport_keepalive_failed():\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 283\u001b[0m found, abandoned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_and_clear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Always update progress to 100% when done\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_progress \u001b[38;5;129;01mand\u001b[39;00m progress_handle \u001b[38;5;129;01mand\u001b[39;00m progress_sent:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py:130\u001b[0m, in \u001b[0;36m_MailboxSlot._get_and_clear\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_and_clear\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[pb\u001b[38;5;241m.\u001b[39mResult], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[0;32m    129\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m             found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py:126\u001b[0m, in \u001b[0;36m_MailboxSlot._wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''# Inicializa una ejecución de WandB\n",
    "wandb.init(project=\"SinapsIA\", entity=\"schajrisgaratiagustina\")\n",
    "\n",
    "# Configura hiperparámetros\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.001\n",
    "config.batch_size = 64'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\X_12.npy')\n",
    "#y = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\y_12.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1790, 224, 224, 3), (1790,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.reshape(1790, 244, 244, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[:,:224,:224,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1790, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "#Cargo el modelo ResNet50 preentrenado\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "#Congelo las capas del modelo base para que no se actualicen en el entrenamiento\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Agrego GlobalAveragePooling2D para adaptar la salida del modelo base\n",
    "#x = GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "#Agrego capas adicionales para la clasificación de mis datos\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(500, activation='relu')(x)  # Puedes usar Dense en lugar de Conv2D aquí\n",
    "x = Dense(200, activation='relu')(x)  # Capas Dense en lugar de MaxPooling2D\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "'''#x = base_model.output\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "x = Conv2D(filters=16, kernel_size=3, activation='relu')(base_model.output)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=16, kernel_size=3, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4, activation='relu')(x)\n",
    "\n",
    "output = Dense(1, activation='softmax')(x)'''\n",
    "\n",
    "#Junto todo y creo el modelo\n",
    "model = Model(inputs=input_tensor, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPILO\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def data_generator():\n",
    "    for i in range(10):\n",
    "        X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_{i+1}.npy')\n",
    "        y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_{i+1}.npy')\n",
    "        yield X, y\n",
    "\n",
    "# https://stackoverflow.com/a/39271995'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.7216 - accuracy: 0.5930 - val_loss: 0.5954 - val_accuracy: 0.6860\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.5784 - accuracy: 0.7075 - val_loss: 0.4413 - val_accuracy: 0.7954\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.5057 - accuracy: 0.7465 - val_loss: 0.4349 - val_accuracy: 0.7976\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.4096 - accuracy: 0.8108 - val_loss: 0.6168 - val_accuracy: 0.7702\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.3396 - accuracy: 0.8521 - val_loss: 0.3542 - val_accuracy: 0.8479\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.2911 - accuracy: 0.8709 - val_loss: 0.2852 - val_accuracy: 0.8851\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.2575 - accuracy: 0.8930 - val_loss: 0.3025 - val_accuracy: 0.8556\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.2288 - accuracy: 0.8986 - val_loss: 0.4160 - val_accuracy: 0.8271\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.2388 - accuracy: 0.8991 - val_loss: 0.2710 - val_accuracy: 0.8895\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.1905 - accuracy: 0.9197 - val_loss: 0.3067 - val_accuracy: 0.8818\n",
      "29/29 [==============================] - 32s 1s/step - loss: 0.3067 - accuracy: 0.8818\n",
      "Accuracy :  0.8818380832672119\n",
      "Loss :  0.3067357838153839\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 112s 2s/step - loss: 0.6820 - accuracy: 0.6353 - val_loss: 0.5639 - val_accuracy: 0.7123\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 111s 2s/step - loss: 0.4528 - accuracy: 0.7927 - val_loss: 0.3862 - val_accuracy: 0.8342\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 111s 2s/step - loss: 0.3378 - accuracy: 0.8555 - val_loss: 0.3008 - val_accuracy: 0.8663\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 112s 2s/step - loss: 0.2666 - accuracy: 0.8922 - val_loss: 0.2651 - val_accuracy: 0.8824\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 112s 2s/step - loss: 0.2391 - accuracy: 0.9023 - val_loss: 0.2687 - val_accuracy: 0.8909\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 115s 2s/step - loss: 0.2140 - accuracy: 0.9119 - val_loss: 0.2026 - val_accuracy: 0.9198\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 112s 2s/step - loss: 0.2032 - accuracy: 0.9202 - val_loss: 0.2221 - val_accuracy: 0.9123\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 113s 2s/step - loss: 0.1690 - accuracy: 0.9344 - val_loss: 0.2825 - val_accuracy: 0.8813\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 115s 2s/step - loss: 0.1652 - accuracy: 0.9381 - val_loss: 0.2147 - val_accuracy: 0.9209\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 113s 2s/step - loss: 0.1377 - accuracy: 0.9491 - val_loss: 0.2225 - val_accuracy: 0.9027\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.2225 - accuracy: 0.9027\n",
      "Accuracy :  0.9026737809181213\n",
      "Loss :  0.22251157462596893\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_{i+1}.npy')\n",
    "    y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_{i+1}.npy')\n",
    "\n",
    "    #DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "    #Divido los datos de train de los de test y evaluation (70/30)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    #para parar el entrenamiento cuando llega a 90\n",
    "    #early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "    #EVALÚO\n",
    "    eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "    del X\n",
    "    del y\n",
    "    del X_val\n",
    "    del y_val\n",
    "    del X_train\n",
    "    del y_train\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Accuracy : \", eval_acc)\n",
    "    print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - 92s 1s/step - loss: 0.7293 - accuracy: 0.5981 - val_loss: 0.5933 - val_accuracy: 0.5930\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 90s 1s/step - loss: 0.5897 - accuracy: 0.5981 - val_loss: 0.5433 - val_accuracy: 0.5930\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 90s 1s/step - loss: 0.5377 - accuracy: 0.5981 - val_loss: 0.5412 - val_accuracy: 0.5930\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 90s 1s/step - loss: 0.4352 - accuracy: 0.5981 - val_loss: 0.3728 - val_accuracy: 0.5930\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 91s 1s/step - loss: 0.3762 - accuracy: 0.5981 - val_loss: 0.3271 - val_accuracy: 0.5930\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 91s 1s/step - loss: 0.3453 - accuracy: 0.5981 - val_loss: 0.2976 - val_accuracy: 0.5930\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 91s 1s/step - loss: 0.2641 - accuracy: 0.5981 - val_loss: 0.2667 - val_accuracy: 0.5930\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 92s 1s/step - loss: 0.2694 - accuracy: 0.5981 - val_loss: 0.2555 - val_accuracy: 0.5930\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 91s 1s/step - loss: 0.2276 - accuracy: 0.5981 - val_loss: 0.2571 - val_accuracy: 0.5930\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 91s 1s/step - loss: 0.2014 - accuracy: 0.5981 - val_loss: 0.2285 - val_accuracy: 0.5930\n",
      "15/15 [==============================] - 16s 1s/step - loss: 0.2285 - accuracy: 0.5930\n",
      "Accuracy :  0.5929977893829346\n",
      "Loss :  0.2284737229347229\n"
     ]
    }
   ],
   "source": [
    "X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_1.npy')\n",
    "y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_1.npy')\n",
    "\n",
    "#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#para parar el entrenamiento cuando llega a 90\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "del X\n",
    "del y\n",
    "del X_val\n",
    "del y_val\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "69/69 [==============================] - 95s 1s/step - loss: 0.7541 - accuracy: 0.5739 - val_loss: 0.6813 - val_accuracy: 0.5610\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.6744 - accuracy: 0.5739 - val_loss: 0.6593 - val_accuracy: 0.5610\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.6401 - accuracy: 0.5739 - val_loss: 0.6028 - val_accuracy: 0.5610\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.5012 - accuracy: 0.5739 - val_loss: 0.3825 - val_accuracy: 0.5610\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.4186 - accuracy: 0.5739 - val_loss: 0.3541 - val_accuracy: 0.5610\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.3299 - accuracy: 0.5739 - val_loss: 0.3243 - val_accuracy: 0.5610\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.2814 - accuracy: 0.5739 - val_loss: 0.2928 - val_accuracy: 0.5610\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.2646 - accuracy: 0.5739 - val_loss: 0.2614 - val_accuracy: 0.5610\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.2278 - accuracy: 0.5739 - val_loss: 0.2254 - val_accuracy: 0.5610\n",
      "Epoch 10/10\n",
      "50/69 [====================>.........] - ETA: 21s - loss: 0.2160 - accuracy: 0.5731"
     ]
    }
   ],
   "source": [
    "X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_2.npy')\n",
    "y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_2.npy')\n",
    "\n",
    "#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#para parar el entrenamiento cuando llega a 90\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "del X\n",
    "del y\n",
    "del X_val\n",
    "del y_val\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_3.npy')\n",
    "y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_3.npy')\n",
    "\n",
    "#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#para parar el entrenamiento cuando llega a 90\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "del X\n",
    "del y\n",
    "del X_val\n",
    "del y_val\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\4.npy')\n",
    "y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_4.npy')\n",
    "\n",
    "#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#para parar el entrenamiento cuando llega a 90\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "del X\n",
    "del y\n",
    "del X_val\n",
    "del y_val\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/67 [=================>............] - ETA: 28s - loss: 0.6025 - accuracy: 0.7783"
     ]
    }
   ],
   "source": [
    "X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_5.npy')\n",
    "y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_5.npy')\n",
    "\n",
    "#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#para parar el entrenamiento cuando llega a 90\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "del X\n",
    "del y\n",
    "del X_val\n",
    "del y_val\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_6.npy')\n",
    "y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_6.npy')\n",
    "\n",
    "#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#para parar el entrenamiento cuando llega a 90\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "del X\n",
    "del y\n",
    "del X_val\n",
    "del y_val\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_7.npy')\n",
    "y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_7.npy')\n",
    "\n",
    "#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#para parar el entrenamiento cuando llega a 90\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "del X\n",
    "del y\n",
    "del X_val\n",
    "del y_val\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_8.npy')\n",
    "y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_8.npy')\n",
    "\n",
    "#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#para parar el entrenamiento cuando llega a 90\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "del X\n",
    "del y\n",
    "del X_val\n",
    "del y_val\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33/33 [==============================] - 54s 2s/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 54s 2s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 54s 2s/step - loss: 2.3941e-04 - accuracy: 1.0000 - val_loss: 7.1710e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 54s 2s/step - loss: 2.1873e-04 - accuracy: 1.0000 - val_loss: 3.3291e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 54s 2s/step - loss: 9.4058e-04 - accuracy: 1.0000 - val_loss: 3.0015e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 54s 2s/step - loss: 4.9740e-04 - accuracy: 1.0000 - val_loss: 2.7708e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 54s 2s/step - loss: 6.2706e-05 - accuracy: 1.0000 - val_loss: 2.4691e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 54s 2s/step - loss: 2.9590e-05 - accuracy: 1.0000 - val_loss: 2.2984e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 54s 2s/step - loss: 2.2462e-05 - accuracy: 1.0000 - val_loss: 2.1111e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 54s 2s/step - loss: 4.3237e-05 - accuracy: 1.0000 - val_loss: 1.6031e-04 - val_accuracy: 1.0000\n",
      "15/15 [==============================] - 16s 1s/step - loss: 1.6031e-04 - accuracy: 1.0000\n",
      "Accuracy :  1.0\n",
      "Loss :  0.00016030733240768313\n"
     ]
    }
   ],
   "source": [
    "X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_9.npy')\n",
    "y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_9.npy')\n",
    "\n",
    "#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#para parar el entrenamiento cuando llega a 90\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "del X\n",
    "del y\n",
    "del X_val\n",
    "del y_val\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_10.npy')\n",
    "y = np.load(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_10.npy')\n",
    "\n",
    "#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#para parar el entrenamiento cuando llega a 90\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='max', verbose=1, baseline=0.9)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "    \n",
    "del X\n",
    "del y\n",
    "del X_val\n",
    "del y_val\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABAJO VOY A TESTEAR CON LOS DATOS QUE NO USÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_entrenado = tf.keras.models.load_model(f'C:\\\\Users\\\\47575909\\\\Desktop\\\\modelo_SinapsIA_SIGMOID_79.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodelo_entrenado\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_classes\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "modelo_entrenado.predict_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 10s 1s/step\n",
      "Probabilidad de tener epilepsia: 0.4249218\n",
      "[[0.9999948 ]\n",
      " [0.99993026]\n",
      " [0.9999456 ]\n",
      " [0.03416435]\n",
      " [0.05418378]\n",
      " [0.31896675]\n",
      " [0.5249109 ]\n",
      " [0.3246847 ]\n",
      " [0.31333873]\n",
      " [0.33310542]\n",
      " [0.5062641 ]\n",
      " [0.8427809 ]\n",
      " [0.35349497]\n",
      " [0.5952718 ]\n",
      " [0.8391339 ]\n",
      " [0.59773815]\n",
      " [0.2144472 ]\n",
      " [0.4976822 ]\n",
      " [0.28451973]\n",
      " [0.4789209 ]\n",
      " [0.401643  ]\n",
      " [0.5452272 ]\n",
      " [0.624994  ]\n",
      " [0.0762439 ]\n",
      " [0.11877525]\n",
      " [0.2138696 ]\n",
      " [0.5447712 ]\n",
      " [0.76375747]\n",
      " [0.7653331 ]\n",
      " [0.60560906]\n",
      " [0.5612265 ]\n",
      " [0.45235023]\n",
      " [0.52263856]\n",
      " [0.5505097 ]\n",
      " [0.75837237]\n",
      " [0.8001266 ]\n",
      " [0.20156442]\n",
      " [0.15673877]\n",
      " [0.786269  ]\n",
      " [0.280881  ]\n",
      " [0.3535062 ]\n",
      " [0.49214447]\n",
      " [0.2864968 ]\n",
      " [0.874659  ]\n",
      " [0.9090262 ]\n",
      " [0.5515237 ]\n",
      " [0.57678795]\n",
      " [0.6922687 ]\n",
      " [0.52214473]\n",
      " [0.28233144]\n",
      " [0.13427973]\n",
      " [0.7176633 ]\n",
      " [0.82249916]\n",
      " [0.84875685]\n",
      " [0.11658891]\n",
      " [0.08869467]\n",
      " [0.17972536]\n",
      " [0.7178708 ]\n",
      " [0.50567913]\n",
      " [0.28270242]\n",
      " [0.40568545]\n",
      " [0.47764954]\n",
      " [0.3574375 ]\n",
      " [0.7140959 ]\n",
      " [0.31170073]\n",
      " [0.15241028]\n",
      " [0.4452153 ]\n",
      " [0.3333652 ]\n",
      " [0.5544276 ]\n",
      " [0.5952319 ]\n",
      " [0.18735765]\n",
      " [0.2552979 ]\n",
      " [0.6806919 ]\n",
      " [0.19214667]\n",
      " [0.7571617 ]\n",
      " [0.56798685]\n",
      " [0.72848904]\n",
      " [0.46407688]\n",
      " [0.6795476 ]\n",
      " [0.6605509 ]\n",
      " [0.65028906]\n",
      " [0.50789887]\n",
      " [0.18756478]\n",
      " [0.4594783 ]\n",
      " [0.07003347]\n",
      " [0.13985364]\n",
      " [0.10060257]\n",
      " [0.13718687]\n",
      " [0.15005504]\n",
      " [0.46523178]\n",
      " [0.15536804]\n",
      " [0.17894495]\n",
      " [0.46765792]\n",
      " [0.50639874]\n",
      " [0.5063625 ]\n",
      " [0.18513776]\n",
      " [0.17799954]\n",
      " [0.5242203 ]\n",
      " [0.43758923]\n",
      " [0.14009216]\n",
      " [0.52589506]\n",
      " [0.53630656]\n",
      " [0.61855584]\n",
      " [0.49801174]\n",
      " [0.2115386 ]\n",
      " [0.25782543]\n",
      " [0.22451302]\n",
      " [0.8021103 ]\n",
      " [0.37992597]\n",
      " [0.49360427]\n",
      " [0.48527187]\n",
      " [0.7976369 ]\n",
      " [0.54435706]\n",
      " [0.48334432]\n",
      " [0.5931253 ]\n",
      " [0.24624182]\n",
      " [0.23722573]\n",
      " [0.39434895]\n",
      " [0.22553179]\n",
      " [0.03385161]\n",
      " [0.07383515]\n",
      " [0.15466678]\n",
      " [0.77413994]\n",
      " [0.9865685 ]\n",
      " [0.57764626]\n",
      " [0.70220727]\n",
      " [0.83091134]\n",
      " [0.7806656 ]\n",
      " [0.71957487]\n",
      " [0.52456194]\n",
      " [0.39855525]\n",
      " [0.1846248 ]\n",
      " [0.92208177]\n",
      " [0.86843127]\n",
      " [0.8682792 ]\n",
      " [0.48820275]\n",
      " [0.47327638]\n",
      " [0.82561225]\n",
      " [0.66449046]\n",
      " [0.6045832 ]\n",
      " [0.6323448 ]\n",
      " [0.1233293 ]\n",
      " [0.18237478]\n",
      " [0.18152367]\n",
      " [0.2053763 ]\n",
      " [0.32813525]\n",
      " [0.10096186]\n",
      " [0.07549951]\n",
      " [0.43577355]\n",
      " [0.08152981]\n",
      " [0.20119192]\n",
      " [0.07892318]\n",
      " [0.0871323 ]\n",
      " [0.13613403]\n",
      " [0.78437644]\n",
      " [0.57229596]\n",
      " [0.4473113 ]\n",
      " [0.7578671 ]\n",
      " [0.25211245]\n",
      " [0.54747546]\n",
      " [0.05677541]\n",
      " [0.05781601]\n",
      " [0.54677933]\n",
      " [0.1673794 ]\n",
      " [0.29828992]\n",
      " [0.14743042]\n",
      " [0.42027655]\n",
      " [0.5251995 ]\n",
      " [0.43897343]\n",
      " [0.19397308]\n",
      " [0.13405141]\n",
      " [0.13467853]\n",
      " [0.06388573]\n",
      " [0.66482645]\n",
      " [0.94697624]\n",
      " [0.68214774]\n",
      " [0.3391312 ]\n",
      " [0.7351086 ]\n",
      " [0.05097964]\n",
      " [0.606547  ]\n",
      " [0.4343085 ]\n",
      " [0.53029704]\n",
      " [0.7809273 ]\n",
      " [0.28534836]\n",
      " [0.33499908]\n",
      " [0.12394504]\n",
      " [0.68329823]\n",
      " [0.8658876 ]\n",
      " [0.8822503 ]\n",
      " [0.71583396]\n",
      " [0.55751806]\n",
      " [0.23456493]\n",
      " [0.5999848 ]\n",
      " [0.57072884]\n",
      " [0.6111131 ]\n",
      " [0.68617797]\n",
      " [0.19628376]\n",
      " [0.12921147]\n",
      " [0.24834172]\n",
      " [0.1520414 ]\n",
      " [0.11013364]\n",
      " [0.12332097]\n",
      " [0.82202476]\n",
      " [0.8573883 ]\n",
      " [0.6818149 ]\n",
      " [0.5307783 ]\n",
      " [0.66981405]\n",
      " [0.12187166]\n",
      " [0.07362464]\n",
      " [0.4007059 ]\n",
      " [0.7290054 ]\n",
      " [0.65588   ]\n",
      " [0.27087337]\n",
      " [0.66602266]\n",
      " [0.20868555]\n",
      " [0.12510104]\n",
      " [0.14201093]\n",
      " [0.31046462]\n",
      " [0.18840067]\n",
      " [0.3568812 ]\n",
      " [0.26048663]\n",
      " [0.40058675]\n",
      " [0.07072414]\n",
      " [0.45680442]\n",
      " [0.52249193]\n",
      " [0.5394688 ]\n",
      " [0.62469536]\n",
      " [0.7098192 ]\n",
      " [0.74804056]\n",
      " [0.4016333 ]\n",
      " [0.19797197]\n",
      " [0.70634747]\n",
      " [0.68781465]\n",
      " [0.60238475]\n",
      " [0.773722  ]\n",
      " [0.355568  ]\n",
      " [0.24622944]\n",
      " [0.14880449]\n",
      " [0.24265431]\n",
      " [0.64276457]\n",
      " [0.5250115 ]\n",
      " [0.07534321]\n",
      " [0.08246551]\n",
      " [0.68470645]\n",
      " [0.6502013 ]\n",
      " [0.29470098]\n",
      " [0.19746666]\n",
      " [0.11176065]\n",
      " [0.07897445]\n",
      " [0.2526279 ]\n",
      " [0.14144789]\n",
      " [0.36252493]\n",
      " [0.14814591]\n",
      " [0.09461016]\n",
      " [0.05630531]\n",
      " [0.04659961]\n",
      " [0.04851189]\n",
      " [0.08613558]\n",
      " [0.56596005]\n",
      " [0.57860905]\n",
      " [0.58559597]\n",
      " [0.64159685]\n",
      " [0.70001936]\n",
      " [0.74804294]\n",
      " [0.06726991]\n",
      " [0.33801305]\n",
      " [0.62898564]\n",
      " [0.57175034]\n",
      " [0.47786304]\n",
      " [0.12390968]\n",
      " [0.14383538]\n",
      " [0.5504352 ]\n",
      " [0.04126517]\n",
      " [0.05680804]\n",
      " [0.52110857]\n",
      " [0.09247857]\n",
      " [0.08854125]\n",
      " [0.10125958]\n",
      " [0.05754619]\n",
      " [0.10364538]\n",
      " [0.06633845]\n",
      " [0.05570409]\n",
      " [0.13398205]\n",
      " [0.6910224 ]\n",
      " [0.5189061 ]\n",
      " [0.33961806]\n",
      " [0.5788548 ]\n",
      " [0.2903774 ]\n",
      " [0.07194995]\n",
      " [0.0834483 ]\n",
      " [0.6985544 ]\n",
      " [0.81517214]\n",
      " [0.8617965 ]\n",
      " [0.8078949 ]\n",
      " [0.6185839 ]\n",
      " [0.42302546]\n",
      " [0.7367265 ]\n",
      " [0.13346677]\n",
      " [0.49398714]]\n"
     ]
    }
   ],
   "source": [
    "prueba_normal = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\X_predict_epilepsy.npy')\n",
    "\n",
    "#HAGO UNA PREDICCIÓN\n",
    "prediction = modelo_entrenado.predict(prueba_normal)\n",
    "\n",
    "epilepsy_prob = np.mean(prediction)\n",
    "\n",
    "print(\"Probabilidad de tener epilepsia:\", epilepsy_prob)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.src.activations.softmax(x, axis=-1)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_entrenado.layers[-1].activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 10s 993ms/step\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "half_prueba = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\X_predict_normal.npy')\n",
    "#HAGO UNA PREDICCIÓN\n",
    "prediction = modelo_entrenado.predict(half_prueba)\n",
    "\n",
    "#probability = np.mean(prediction)\n",
    "#epilepsy_prob = prediction[:, 1]\n",
    "#print(\"Probabilidad de tener epilepsia:\", epilepsy_prob)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(modelo_entrenado, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 85s 1s/step - loss: 1.7050 - accuracy: 0.4347\n",
      "74/74 [==============================] - 84s 1s/step - loss: 1.5443 - accuracy: 0.4563\n",
      "16/74 [=====>........................] - ETA: 1:07 - loss: 3.3450 - accuracy: 0.1836"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m partes_y\u001b[38;5;241m.\u001b[39mappend(y[inicio:])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (parte_X, parte_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(partes_X, partes_y)):\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparte_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparte_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2272\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2268\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   2269\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2270\u001b[0m             ):\n\u001b[0;32m   2271\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2272\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2274\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2276\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2277\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2279\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2280\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:4079\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[1;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[0;32m   4078\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[1;32m-> 4079\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   4081\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 876\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    880\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cargar los archivos X e y\n",
    "X = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_4.npy')\n",
    "y = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_4.npy')\n",
    "\n",
    "# Especificar el número de partes en las que deseas dividir los archivos\n",
    "num_partes = 4\n",
    "\n",
    "# Calcular el tamaño de cada parte\n",
    "tamaño_parte_X = len(X) // num_partes\n",
    "tamaño_parte_y = len(y) // num_partes\n",
    "\n",
    "# Dividir los archivos en partes\n",
    "partes_X = []\n",
    "partes_y = []\n",
    "inicio = 0\n",
    "for i in range(num_partes - 1):\n",
    "    partes_X.append(X[inicio:inicio + tamaño_parte_X])\n",
    "    partes_y.append(y[inicio:inicio + tamaño_parte_y])\n",
    "    inicio += tamaño_parte_X\n",
    "\n",
    "# Añadir la última parte (puede que tenga un tamaño diferente si la longitud no es divisible por el número de partes)\n",
    "partes_X.append(X[inicio:])\n",
    "partes_y.append(y[inicio:])\n",
    "\n",
    "for i, (parte_X, parte_y) in enumerate(zip(partes_X, partes_y)):\n",
    "    model.evaluate(parte_X, parte_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''X = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\X_1.npy')\n",
    "y = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset\\\\y_1.npy')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "    #Divido los datos de train de los de test y evaluation (70/30)\n",
    "    X_train, X_testVal, y_train, y_testVal = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    #Divido los datos de test de los de evaluation (50/50 del 30% anterior)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_testVal, y_testVal, test_size=0.5, random_state=42)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 9/96 [=>............................] - ETA: 1:39 - loss: 0.9005 - accuracy: 0.6111"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[wandb.keras.WandbCallback())\n",
    "\n",
    "#EVALÚO\n",
    "eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "\n",
    "wandb.log({\"eval_loss\": test_loss, \"eval_acc\": test_acc})'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(\"Accuracy : \", eval_acc)\n",
    "print(\"Loss : \", eval_loss'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (1637144083.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[wandb.keras.WandbCallback())\u001b[0m\n\u001b[1;37m                                                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "'''def model_train(archivo_x, archivo_y):\n",
    "    X = np.load(archivo_x)\n",
    "    y = np.load(archivo_y)\n",
    "\n",
    "    #DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "    #Divido los datos de train de los de test y evaluation (70/30)\n",
    "    X_train, X_testVal, y_train, y_testVal = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    #Divido los datos de test de los de evaluation (50/50 del 30% anterior)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_testVal, y_testVal, test_size=0.5, random_state=42)\n",
    "\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[wandb.keras.WandbCallback())\n",
    "\n",
    "    #EVALÚO\n",
    "    eval_loss, eval_acc = model.evaluate(X_val, y_val)\n",
    "\n",
    "    wandb.log({\"eval_loss\": test_loss, \"eval_acc\": test_acc})\n",
    "\n",
    "    #VEO LA PERFORMANCE\n",
    "    print(\"Accuracy : \", eval_acc)\n",
    "    print(\"Loss : \", eval_loss)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [8181, 2727]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m archivo_x \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directorio, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m archivo_y \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directorio, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchivo_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchivo_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m, in \u001b[0;36mmodel_train\u001b[1;34m(archivo_x, archivo_y)\u001b[0m\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(archivo_y)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#DIVIDO EN TRAIN, TEST Y EVALUATION\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Divido los datos de train de los de test y evaluation (70/30)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X_train, X_testVal, y_train, y_testVal \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#Divido los datos de test de los de evaluation (50/50 del 30% anterior)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X_val, X_test, y_val, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_testVal, y_testVal, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2646\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2646\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2648\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2649\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2650\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2651\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:453\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    452\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 453\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [8181, 2727]"
     ]
    }
   ],
   "source": [
    "'''directorio = 'C:\\\\Users\\\\47575909\\\\Desktop\\\\Dataset'\n",
    "num_archivos = 10\n",
    "\n",
    "for i in range(1, num_archivos + 1):\n",
    "    archivo_x = os.path.join(directorio, f'X_{i}.npy')\n",
    "    archivo_y = os.path.join(directorio, f'y_{i}.npy')\n",
    "\n",
    "    model_train(archivo_x, archivo_y)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''X = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\X.npy')\n",
    "y = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\y.npy')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#DIVIDO EN TRAIN, TEST Y EVALUATION\n",
    "#Divido los datos de train de los de test y evaluation (70/30)\n",
    "X_train, X_testVal, y_train, y_testVal = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Divido los datos de test de los de evaluation (50/50 del 30% anterior)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_testVal, y_testVal, test_size=0.5, random_state=42)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#ENTRENO\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#EVALÚO\n",
    "test_loss, test_acc = model.evaluate(X_val, y_val)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#VEO LA PERFORMANCE\n",
    "print(\"Accuracy : \", test_acc)\n",
    "print(\"Loss : \", test_loss)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 10s 1s/step\n",
      "6.024863e-08\n"
     ]
    }
   ],
   "source": [
    "prueba_normal = np.load('C:\\\\Users\\\\47575909\\\\Desktop\\\\X_predict_epilepsy.npy')\n",
    "\n",
    "#HAGO UNA PREDICCIÓN\n",
    "prediction = model.predict(prueba_normal)\n",
    "\n",
    "probability = np.mean(prediction)\n",
    "#epilepsy_prob = prediction[:, 1]\n",
    "#print(\"Probabilidad de tener epilepsia:\", epilepsy_prob)\n",
    "\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decirle a chona que el indio usa ResNet-26D y que keras no lo tiene ese. Que hago?...\n",
    "- Uso otro modelo de ResNet\n",
    "- Uso las liberías pytorch y timm que si tienen el ResNet-26D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportamos el modelo\n",
    "(Con tensorflow.js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardamos el modelo\n",
    "model.save('modelo_SinapsIA_SIGMOID_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Exportamos el modelooo\n",
    "tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model --signature_name=serving_default --saved_model_tags=serve /ruta/al/modelo/saved_model /ruta/de/destino/\n",
    "#che, no entiendo lo de las rutas'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "//HABRÍA QUE HACER ESTO PARA QUE ME DEVUELVA EN LA WEB SOLO LA PROBABILIDAD QUE YO QUIERO (la probabilidad de tener epilepsia)\n",
    "\n",
    "// Obtener datos de entrada (pueden ser simulados en este ejemplo)\n",
    "const datosEntrada = obtenerDatosDeEntrada();\n",
    "\n",
    "// Cargar el modelo\n",
    "const modelo = await cargarModelo();\n",
    "\n",
    "// Realizar predicciones\n",
    "const predicciones = modelo.predict(tf.tensor(datosEntrada));\n",
    "\n",
    "// Mostrar la probabilidad de tener epilepsia\n",
    "const probabilidadEpilepsia = predicciones.mean();\n",
    "console.log('Probabilidad de tener epilepsia:', probabilidadEpilepsia);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
